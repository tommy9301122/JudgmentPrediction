{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from C:\\Users\\user\\Desktop\\Python\\判決書\\損害賠償\\dict.txt ...\n",
      "Loading model from cache C:\\Users\\user\\AppData\\Local\\Temp\\jieba.u199ece6fffe78be19b7dda1547b04bc1.cache\n",
      "Loading model cost 0.640 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.set_printoptions(threshold=np.nan)\n",
    "\n",
    "import jieba\n",
    "jieba.set_dictionary('dict.txt')                  # 繁體字典\n",
    "jieba.load_userdict('special_v3.txt')             # 法律專用詞字典\n",
    "#with open('stop.txt', encoding='utf_8') as f:    # 停止字字典\n",
    "#    stops = f.read().split('\\n')\n",
    "import re\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import keras\n",
    "from keras import Input\n",
    "from keras import backend as K\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.engine.topology import Layer\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.utils import to_categorical, plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 資料前置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('CFD_all_Y_v4.csv',encoding='utf_8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4531\n",
       "0    4531\n",
       "Name: 判決主文類別, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df為所有損害賠償判決書  DF為分類標籤整理為1:1的判決書資料\n",
    "\n",
    "df = df.dropna(subset = ['案件描述','判決主文類別'])\n",
    "df = df[df['判決主文類別'] != 3]\n",
    "df1 = df[df['判決主文類別'] == 1]\n",
    "df2 = df[df['判決主文類別'] == 2]\n",
    "df3 = df1.sample(len(df2), random_state=87)\n",
    "DF = pd.concat([df3, df2])\n",
    "DF['判決主文類別'] = DF['判決主文類別']-1\n",
    "DF = DF.sample(frac=1)                       # 打亂順序\n",
    "\n",
    "DF['判決主文類別'].value_counts()             # 1代表原告訴求駁回"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文字處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 主文斷詞斷句\n",
    "\n",
    "main_text = DF['案件描述'].tolist()\n",
    "cat_list = DF['判決主文類別'].tolist()\n",
    "\n",
    "# 主文斷詞  ['第一篇', '第二篇']\n",
    "main_text_list = [' '.join(jieba.cut( txt, cut_all=False)) for txt in main_text]\n",
    "\n",
    "# 主文斷句  [['第一篇第一句','第一篇第二句'], ['第二篇第一句','第二篇第二句']]\n",
    "main_sentence_list = [re.split('，|。', i) for i in main_text_list]             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重要參數\n",
    "\n",
    "MAX_SENT_LENGTH = 20    # 單句最大詞數\n",
    "MAX_SENTS = 100         # 單篇最多句數\n",
    "MAX_NB_WORDS = 150000   # 字典上限\n",
    "EMBEDDING_DIM = 100     # 詞向量維度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:(樣本數, 單篇最多句數, 單句最大詞數) (9062, 100, 20)\n",
      "labels: (9062, 2)\n"
     ]
    }
   ],
   "source": [
    "# 文字資料前處理\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(main_text_list)\n",
    "\n",
    "# 訂好矩陣形狀 (樣本數, 單篇文章最多句數, 單句最大詞數)\n",
    "data = np.zeros((len(main_text_list), MAX_SENTS, MAX_SENT_LENGTH), dtype='int32')   \n",
    "\n",
    "# 多切掉少補零 (補在後面)\n",
    "for i, sentences in enumerate(main_sentence_list):\n",
    "    for j, sent in enumerate(sentences):\n",
    "        if j< MAX_SENTS:\n",
    "            wordTokens = text_to_word_sequence(sent)\n",
    "            k=0\n",
    "            for _, word in enumerate(wordTokens):\n",
    "                if k<MAX_SENT_LENGTH and tokenizer.word_index[word]<MAX_NB_WORDS:\n",
    "                    data[i,j,k] = tokenizer.word_index[word]\n",
    "                    k=k+1                    \n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "labels = to_categorical(np.asarray(cat_list))\n",
    "print('data:(樣本數, 單篇最多句數, 單句最大詞數)', data.shape)\n",
    "print('labels:', labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 切訓練、驗證、測試資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_SPLIT = 0.1     # 驗証資料比例\n",
    "TEST_SPLIT = 0.1           # 測試資料比例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train : 7249\n",
      "val : 906\n",
      "test : 907\n"
     ]
    }
   ],
   "source": [
    "# 訓練資料 驗證資料 測試資料\n",
    "\n",
    "p1 = int(len(data)*(1-VALIDATION_SPLIT-TEST_SPLIT))\n",
    "p2 = int(len(data)*(1-TEST_SPLIT))\n",
    "\n",
    "x_train = data[:p1]\n",
    "y_train = labels[:p1]\n",
    "\n",
    "x_val = data[p1:p2]\n",
    "y_val = labels[p1:p2]\n",
    "\n",
    "x_test = data[p2:]\n",
    "y_test = labels[p2:]\n",
    "\n",
    "print( 'train : '+str(len(x_train)) )\n",
    "print( 'val : '+str(len(x_val)) )\n",
    "print( 'test : '+str(len(x_test)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全零 Array，用於Attention層的非監督學習\n",
    "\n",
    "y_train_sent_score = np.zeros((len(y_train), MAX_SENTS))\n",
    "y_train_word_score = np.zeros((len(y_train), MAX_SENT_LENGTH))\n",
    "y_val_sent_score = np.zeros((len(y_val), MAX_SENTS))\n",
    "y_val_word_score = np.zeros((len(y_val), MAX_SENT_LENGTH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型建構"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 詞向量-Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 排列順序按照Tokenizer在fit之後的詞順序，作為權重餵給 embedding Layer\n",
    "\n",
    "# 讀取預先訓練好的word2vec模型\n",
    "w2v_model = Word2Vec.load(\"w2v_model.model\")\n",
    "\n",
    "# 因Keras保留一層全零層所以需要加1\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))                    \n",
    "\n",
    "# 將word_list對應到word2vec詞向量\n",
    "for word, i in word_index.items(): \n",
    "    if str(word) in w2v_model:\n",
    "        embedding_matrix[i] = np.asarray(w2v_model[str(word)],dtype='float32')       \n",
    "        \n",
    "# 設定word2vec為embedding層\n",
    "embedding_layer = Embedding(len(word_index) + 1,                                    \n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],                              \n",
    "                            input_length=MAX_SENT_LENGTH,\n",
    "                            trainable=False)  # 已經訓練過word2vec了，因此不加入Keras訓練"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention層"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義Attention層\n",
    "\n",
    "'''\n",
    "代碼來源：https://gist.github.com/cbaziotis/6428df359af27d58078ca5ed9792bd6d\n",
    "論文：https://arxiv.org/abs/1512.08756\n",
    "\n",
    "'''\n",
    "\n",
    "def dot_product(x, kernel):\n",
    "    if K.backend() == 'tensorflow':\n",
    "        # todo: check that this is correct\n",
    "        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n",
    "    else:\n",
    "        return K.dot(x, kernel)\n",
    "\n",
    "class Attention(Layer):\n",
    "    def __init__(self,\n",
    "                 W_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                 bias=True,\n",
    "                 return_attention=False,\n",
    "                 **kwargs):\n",
    "        self.supports_masking = True\n",
    "        self.return_attention = return_attention\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "        self.bias = bias\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "        self.W = self.add_weight((input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight((input_shape[1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "        else:\n",
    "            self.b = None\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        eij = dot_product(x, self.W)\n",
    "        if self.bias:\n",
    "            eij += self.b\n",
    "        eij = K.tanh(eij)\n",
    "        a = K.exp(eij)\n",
    "        # apply mask after the exp. will be re-normalized next\n",
    "        if mask is not None:\n",
    "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "        # a /= K.cast(K.sum(a, axis=1, keepdims=True), K.floatx())\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "        weighted_input = x * K.expand_dims(a)\n",
    "        result = K.sum(weighted_input, axis=1)\n",
    "        if self.return_attention:\n",
    "            return [result, a]\n",
    "        return result\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if self.return_attention:\n",
    "            return [(input_shape[0], input_shape[-1]),\n",
    "                    (input_shape[0], input_shape[1])]\n",
    "        else:\n",
    "            return input_shape[0], input_shape[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras建構模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w2v_GRU_Attention\n",
    "\n",
    "\"\"\"\n",
    "模型結構：\n",
    " 案件描述輸入 > 句子輸入 > word2vec詞向量 > 雙向GRU > Attention層 (產出詞重要度) > 連接層 >\n",
    "                                         雙向GRU > Attention層 (產出句子重要度) > 連接層 > 判決結果\n",
    "model input: 案件描述\n",
    "model output: 判決結果、句子重要度\n",
    "\n",
    "model2 input: 句子\n",
    "model2 output: 詞重要度\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "sentence_input = Input(shape=(MAX_SENT_LENGTH,), dtype='int32')\n",
    "l_embedded = embedding_layer(sentence_input)\n",
    "l_lstm = Bidirectional(GRU(100, dropout=0.2, return_sequences=True))(l_embedded)\n",
    "l_att, word_scores = Attention(return_attention=True)(l_lstm)\n",
    "l_dense = Dense(100, activation='relu')(l_att)\n",
    "Word_Model = Model(sentence_input, l_dense)\n",
    "\n",
    "verdict_input = Input(shape=(MAX_SENTS, MAX_SENT_LENGTH), dtype='int32')\n",
    "verdict_encoder = TimeDistributed(Word_Model)(verdict_input)\n",
    "l_lstm_sent = Bidirectional(GRU(100, dropout=0.2, return_sequences=True))(verdict_encoder)\n",
    "l_att_sent, sentence_scores = Attention(return_attention=True)(l_lstm_sent)\n",
    "l_dense_sent = Dense(100, activation='relu')(l_att_sent)\n",
    "preds = Dense(labels.shape[1], activation='softmax')(l_dense_sent)\n",
    "\n",
    "\n",
    "model = Model(verdict_input, output=(preds, sentence_scores))\n",
    "model2 = Model(sentence_input, output=(word_scores))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', loss_weights=[1,0], optimizer='rmsprop', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 100, 20)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 100, 100)          13715820  \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 100, 200)          120600    \n",
      "_________________________________________________________________\n",
      "attention_3 (Attention)      [(None, 200), (None, 100) 300       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 13,857,022\n",
      "Trainable params: 282,122\n",
      "Non-trainable params: 13,574,900\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 模型一 : 分類結果與句的權重\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "embedding_3 (Embedding)      (None, 20, 100)           13574900  \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 20, 200)           120600    \n",
      "_________________________________________________________________\n",
      "attention_2 (Attention)      [(None, 200), (None, 20)] 220       \n",
      "=================================================================\n",
      "Total params: 13,695,720\n",
      "Trainable params: 120,820\n",
      "Non-trainable params: 13,574,900\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 模型二 : 字的權重\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7249 samples, validate on 906 samples\n",
      "Epoch 1/3\n",
      "7249/7249 [==============================] - 361s 50ms/step - loss: 0.4270 - dense_4_loss: 0.4270 - attention_3_loss: 0.0101 - dense_4_acc: 0.7991 - attention_3_acc: 1.0000 - val_loss: 0.4018 - val_dense_4_loss: 0.4018 - val_attention_3_loss: 0.0101 - val_dense_4_acc: 0.8168 - val_attention_3_acc: 1.0000\n",
      "Epoch 2/3\n",
      "7249/7249 [==============================] - 357s 49ms/step - loss: 0.3974 - dense_4_loss: 0.3974 - attention_3_loss: 0.0101 - dense_4_acc: 0.8154 - attention_3_acc: 1.0000 - val_loss: 0.3974 - val_dense_4_loss: 0.3974 - val_attention_3_loss: 0.0101 - val_dense_4_acc: 0.8157 - val_attention_3_acc: 1.0000\n",
      "Epoch 3/3\n",
      "7249/7249 [==============================] - 358s 49ms/step - loss: 0.3812 - dense_4_loss: 0.3812 - attention_3_loss: 0.0101 - dense_4_acc: 0.8255 - attention_3_acc: 1.0000 - val_loss: 0.4155 - val_dense_4_loss: 0.4155 - val_attention_3_loss: 0.0101 - val_dense_4_acc: 0.8146 - val_attention_3_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2123d55d7b8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FIT起來 !!!!!\n",
    "\n",
    "model.fit(x_train, [y_train, y_train_sent_score], epochs=3, validation_data=([x_val, [y_val, y_val_sent_score]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data Acc : 0.8302094818081588\n"
     ]
    }
   ],
   "source": [
    "# 模型測試資料判決準確率\n",
    "\n",
    "Y_test = y_test.dot([0,1])\n",
    "test_pred_label = np.argmax(model.predict(x_test)[0], axis=1)\n",
    "\n",
    "accuracy=accuracy_score(Y_test ,test_pred_label)\n",
    "print('Test Data Acc : '+str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 輸出model結果(判決預測、句子重要度)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 測試資料丟模型跑結果\n",
    "\n",
    "y_test_pred = model.predict(x_test)\n",
    "\n",
    "y_test_pred_label = y_test_pred[0]    # 判決結果\n",
    "y_test_pred_score = y_test_pred[1]    # 句子重要度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 測試用文章\n",
    "\n",
    "test_victor = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test_pred_score[test_victor]        # 測試用文章句子重要度\n",
    "# y_test_pred_score[test_victor].sum()  # 權重相加要約等於1 (會有np浮點數計算誤差)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將數字映回文字\n",
    "\n",
    "sentences = x_test[test_victor].tolist()\n",
    "reverse_word_map = dict(map(reversed, tokenizer.word_index.items())) # 將 word_index 字典反過來\n",
    "\n",
    "def sequence_to_text(list_of_indices):\n",
    "    words = [reverse_word_map.get(letter) for letter in list_of_indices]\n",
    "    return(words)\n",
    "sent_list = list(map(sequence_to_text, sentences)) # 對映回來"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 整理為 dataframe\n",
    "\n",
    "df_match_attscore = pd.DataFrame()\n",
    "sent_se = pd.Series(sent_list)\n",
    "df_match_attscore['句子'] = sent_se.values\n",
    "weight_list = y_test_pred_score[test_victor].tolist()\n",
    "weight_se = pd.Series(weight_list)\n",
    "df_match_attscore['分數'] = weight_se.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.781666  , 0.21833403], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 判決結果\n",
    "\n",
    "y_test_pred_label[test_victor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>句子</th>\n",
       "      <th>分數</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[原告, 主張, ：, 被告, 羅栩亮, 為, 兆良, 科技, 股份有限公司, （, 下稱,...</td>\n",
       "      <td>0.031984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[被告, 黃泳學, 為, 投資, 未, 上市, 、, 上櫃, 公司股票, 並, 非法, 經營...</td>\n",
       "      <td>0.031984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[兆良, 公司, 透過, 電話, 承銷, None, None, None, None, N...</td>\n",
       "      <td>0.031961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[並, 利用, 媒體, 向, 投資人, 喊話, None, None, None, None...</td>\n",
       "      <td>0.031883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[宣稱, 兆良, 公司, 和, 國際, 醫療, 器材, 大, 廠, 合作, None, No...</td>\n",
       "      <td>0.031937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[簽署, 備忘錄, None, None, None, None, None, None, ...</td>\n",
       "      <td>0.031939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[原告, 受此, 吸引, 乃, 投資, 購買, 兆良, 公司, 未, 上市, 股票, Non...</td>\n",
       "      <td>0.031985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[惟, 兆良, 公司, 確屬, 空殼, 公司, 而, 有, 詐騙, 投資人, 之, 事實, ...</td>\n",
       "      <td>0.031988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[原告, 因, 被告, 共同, 故意, 詐欺, 之, 行為, 而, 受騙, None, No...</td>\n",
       "      <td>0.031988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[先後, 於, 民國, 103, 年, 6, 月, 3, 日, 、, 同年, 8, 月, 1...</td>\n",
       "      <td>0.031988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[交付, 股款, 金額, 分別, 為, 新臺幣, （, 下同, ）, 134000, 元, ...</td>\n",
       "      <td>0.031973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[共計, 184000, 元, None, None, None, None, None, ...</td>\n",
       "      <td>0.031835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[原告, 因此, 受有損害, None, None, None, None, None, N...</td>\n",
       "      <td>0.030485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[爰, 依, 侵權行為, 之, 法律關係, 提起, 本件, 訴訟, 等語, None, No...</td>\n",
       "      <td>0.015095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[並, 聲明, ：, 被告, 應, 連帶, 給付, 原告, 184000, 元, None,...</td>\n",
       "      <td>0.009179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[及, 自, 起訴狀, 繕本, 送達, 翌日, 起至, 清償日, 止, None, None...</td>\n",
       "      <td>0.009747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[按, 週年, 利率, 5, 計算, 之, 利息, ；, 願, 供擔保, None, Non...</td>\n",
       "      <td>0.006465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[請准, 宣告, 假執行, None, None, None, None, None, No...</td>\n",
       "      <td>0.006139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[三, 、, \\r, \\r, 被告, 則以, ：, 被告, 羅栩亮, 部, 分, ：, 原告...</td>\n",
       "      <td>0.007327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[故, 被告, 羅栩亮, 就, 原告, 之, 請求, 為, 認諾, 之, 表示, 等語, N...</td>\n",
       "      <td>0.008563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[被告, 黃泳學, 部, 分, ：, 被告, 黃泳學, 未, 於, 言詞辯論, 期日, 到場...</td>\n",
       "      <td>0.012387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[據, 其, 提出, 之, 書狀, 所, 為之, 聲明, 及, 陳述, 如下, ：, 被告,...</td>\n",
       "      <td>0.029540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[被告, 黃泳學, 對, 兆良, 公司, 營運, 狀況, 不佳, 乙事並, 不, 知情, N...</td>\n",
       "      <td>0.031140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[無, 與, 被告, 羅栩亮, 共同, 詐欺, 原告, 之意, None, None, No...</td>\n",
       "      <td>0.031986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[自, 不得, 謂, 被告, 黃泳學, 有, 與, 被告, 羅栩亮, 成立, 共同, 侵權行...</td>\n",
       "      <td>0.031968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[資為, 抗辯, None, None, None, None, None, None, N...</td>\n",
       "      <td>0.029882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[並, 聲明, ：, 原告, 之訴, 駁回, ；, 如受, 不利, 判決, None, No...</td>\n",
       "      <td>0.025319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[願, 供擔保, 請准, 宣告, 免為, 假執行, None, None, None, No...</td>\n",
       "      <td>0.014158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[四, 、, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.007092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.005248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>0.004352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   句子        分數\n",
       "0   [原告, 主張, ：, 被告, 羅栩亮, 為, 兆良, 科技, 股份有限公司, （, 下稱,...  0.031984\n",
       "1   [被告, 黃泳學, 為, 投資, 未, 上市, 、, 上櫃, 公司股票, 並, 非法, 經營...  0.031984\n",
       "2   [兆良, 公司, 透過, 電話, 承銷, None, None, None, None, N...  0.031961\n",
       "3   [並, 利用, 媒體, 向, 投資人, 喊話, None, None, None, None...  0.031883\n",
       "4   [宣稱, 兆良, 公司, 和, 國際, 醫療, 器材, 大, 廠, 合作, None, No...  0.031937\n",
       "5   [簽署, 備忘錄, None, None, None, None, None, None, ...  0.031939\n",
       "6   [原告, 受此, 吸引, 乃, 投資, 購買, 兆良, 公司, 未, 上市, 股票, Non...  0.031985\n",
       "7   [惟, 兆良, 公司, 確屬, 空殼, 公司, 而, 有, 詐騙, 投資人, 之, 事實, ...  0.031988\n",
       "8   [原告, 因, 被告, 共同, 故意, 詐欺, 之, 行為, 而, 受騙, None, No...  0.031988\n",
       "9   [先後, 於, 民國, 103, 年, 6, 月, 3, 日, 、, 同年, 8, 月, 1...  0.031988\n",
       "10  [交付, 股款, 金額, 分別, 為, 新臺幣, （, 下同, ）, 134000, 元, ...  0.031973\n",
       "11  [共計, 184000, 元, None, None, None, None, None, ...  0.031835\n",
       "12  [原告, 因此, 受有損害, None, None, None, None, None, N...  0.030485\n",
       "13  [爰, 依, 侵權行為, 之, 法律關係, 提起, 本件, 訴訟, 等語, None, No...  0.015095\n",
       "14  [並, 聲明, ：, 被告, 應, 連帶, 給付, 原告, 184000, 元, None,...  0.009179\n",
       "15  [及, 自, 起訴狀, 繕本, 送達, 翌日, 起至, 清償日, 止, None, None...  0.009747\n",
       "16  [按, 週年, 利率, 5, 計算, 之, 利息, ；, 願, 供擔保, None, Non...  0.006465\n",
       "17  [請准, 宣告, 假執行, None, None, None, None, None, No...  0.006139\n",
       "18  [三, 、, \\r, \\r, 被告, 則以, ：, 被告, 羅栩亮, 部, 分, ：, 原告...  0.007327\n",
       "19  [故, 被告, 羅栩亮, 就, 原告, 之, 請求, 為, 認諾, 之, 表示, 等語, N...  0.008563\n",
       "20  [被告, 黃泳學, 部, 分, ：, 被告, 黃泳學, 未, 於, 言詞辯論, 期日, 到場...  0.012387\n",
       "21  [據, 其, 提出, 之, 書狀, 所, 為之, 聲明, 及, 陳述, 如下, ：, 被告,...  0.029540\n",
       "22  [被告, 黃泳學, 對, 兆良, 公司, 營運, 狀況, 不佳, 乙事並, 不, 知情, N...  0.031140\n",
       "23  [無, 與, 被告, 羅栩亮, 共同, 詐欺, 原告, 之意, None, None, No...  0.031986\n",
       "24  [自, 不得, 謂, 被告, 黃泳學, 有, 與, 被告, 羅栩亮, 成立, 共同, 侵權行...  0.031968\n",
       "25  [資為, 抗辯, None, None, None, None, None, None, N...  0.029882\n",
       "26  [並, 聲明, ：, 原告, 之訴, 駁回, ；, 如受, 不利, 判決, None, No...  0.025319\n",
       "27  [願, 供擔保, 請准, 宣告, 免為, 假執行, None, None, None, No...  0.014158\n",
       "28  [四, 、, None, None, None, None, None, None, Non...  0.007092\n",
       "29  [None, None, None, None, None, None, None, Non...  0.005248\n",
       "30  [None, None, None, None, None, None, None, Non...  0.004656\n",
       "31  [None, None, None, None, None, None, None, Non...  0.004481\n",
       "32  [None, None, None, None, None, None, None, Non...  0.004437\n",
       "33  [None, None, None, None, None, None, None, Non...  0.004404\n",
       "34  [None, None, None, None, None, None, None, Non...  0.004389\n",
       "35  [None, None, None, None, None, None, None, Non...  0.004377\n",
       "36  [None, None, None, None, None, None, None, Non...  0.004369\n",
       "37  [None, None, None, None, None, None, None, Non...  0.004360\n",
       "38  [None, None, None, None, None, None, None, Non...  0.004358\n",
       "39  [None, None, None, None, None, None, None, Non...  0.004356\n",
       "40  [None, None, None, None, None, None, None, Non...  0.004354\n",
       "41  [None, None, None, None, None, None, None, Non...  0.004354\n",
       "42  [None, None, None, None, None, None, None, Non...  0.004352\n",
       "43  [None, None, None, None, None, None, None, Non...  0.004349\n",
       "44  [None, None, None, None, None, None, None, Non...  0.004348\n",
       "45  [None, None, None, None, None, None, None, Non...  0.004349\n",
       "46  [None, None, None, None, None, None, None, Non...  0.004347\n",
       "47  [None, None, None, None, None, None, None, Non...  0.004346\n",
       "48  [None, None, None, None, None, None, None, Non...  0.004345\n",
       "49  [None, None, None, None, None, None, None, Non...  0.004344\n",
       "50  [None, None, None, None, None, None, None, Non...  0.004343\n",
       "51  [None, None, None, None, None, None, None, Non...  0.004343\n",
       "52  [None, None, None, None, None, None, None, Non...  0.004344\n",
       "53  [None, None, None, None, None, None, None, Non...  0.004343\n",
       "54  [None, None, None, None, None, None, None, Non...  0.004342\n",
       "55  [None, None, None, None, None, None, None, Non...  0.004343\n",
       "56  [None, None, None, None, None, None, None, Non...  0.004344\n",
       "57  [None, None, None, None, None, None, None, Non...  0.004345\n",
       "58  [None, None, None, None, None, None, None, Non...  0.004345\n",
       "59  [None, None, None, None, None, None, None, Non...  0.004344\n",
       "60  [None, None, None, None, None, None, None, Non...  0.004343\n",
       "61  [None, None, None, None, None, None, None, Non...  0.004344\n",
       "62  [None, None, None, None, None, None, None, Non...  0.004344\n",
       "63  [None, None, None, None, None, None, None, Non...  0.004344\n",
       "64  [None, None, None, None, None, None, None, Non...  0.004343\n",
       "65  [None, None, None, None, None, None, None, Non...  0.004344\n",
       "66  [None, None, None, None, None, None, None, Non...  0.004345\n",
       "67  [None, None, None, None, None, None, None, Non...  0.004345\n",
       "68  [None, None, None, None, None, None, None, Non...  0.004344\n",
       "69  [None, None, None, None, None, None, None, Non...  0.004344\n",
       "70  [None, None, None, None, None, None, None, Non...  0.004343\n",
       "71  [None, None, None, None, None, None, None, Non...  0.004344\n",
       "72  [None, None, None, None, None, None, None, Non...  0.004342\n",
       "73  [None, None, None, None, None, None, None, Non...  0.004342\n",
       "74  [None, None, None, None, None, None, None, Non...  0.004343\n",
       "75  [None, None, None, None, None, None, None, Non...  0.004342\n",
       "76  [None, None, None, None, None, None, None, Non...  0.004344\n",
       "77  [None, None, None, None, None, None, None, Non...  0.004343\n",
       "78  [None, None, None, None, None, None, None, Non...  0.004343\n",
       "79  [None, None, None, None, None, None, None, Non...  0.004343\n",
       "80  [None, None, None, None, None, None, None, Non...  0.004342\n",
       "81  [None, None, None, None, None, None, None, Non...  0.004342\n",
       "82  [None, None, None, None, None, None, None, Non...  0.004342\n",
       "83  [None, None, None, None, None, None, None, Non...  0.004342\n",
       "84  [None, None, None, None, None, None, None, Non...  0.004342\n",
       "85  [None, None, None, None, None, None, None, Non...  0.004341\n",
       "86  [None, None, None, None, None, None, None, Non...  0.004343\n",
       "87  [None, None, None, None, None, None, None, Non...  0.004342\n",
       "88  [None, None, None, None, None, None, None, Non...  0.004342\n",
       "89  [None, None, None, None, None, None, None, Non...  0.004341\n",
       "90  [None, None, None, None, None, None, None, Non...  0.004342\n",
       "91  [None, None, None, None, None, None, None, Non...  0.004342\n",
       "92  [None, None, None, None, None, None, None, Non...  0.004342\n",
       "93  [None, None, None, None, None, None, None, Non...  0.004342\n",
       "94  [None, None, None, None, None, None, None, Non...  0.004342\n",
       "95  [None, None, None, None, None, None, None, Non...  0.004342\n",
       "96  [None, None, None, None, None, None, None, Non...  0.004343\n",
       "97  [None, None, None, None, None, None, None, Non...  0.004343\n",
       "98  [None, None, None, None, None, None, None, Non...  0.004346\n",
       "99  [None, None, None, None, None, None, None, Non...  0.004352"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 句子重要度\n",
    "\n",
    "pd.set_option(\"display.max_rows\",100)\n",
    "df_match_attscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 存檔\n",
    "# df_match_attscore.to_csv('案例1Attention.csv', encoding='utf_8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
